program: DRL-Traj-Planner/src/continous_training_sweep.py
method: grid
metric:
  name: eval/episode_success
  goal: maximize
parameters:
  algo:
    value: "sac"
  map_key:
    value: "random"
  reward_mode:
    value: "curriculum_step"
  env_name:
    value: "TrajectoryPlannerEnvironmentImgsReward3-v0"
  seed:
    values: [1235, 2621, 12, 52, 27345, 5, 1346, 6455, 86, 22]
  sac:
    parameters:
      total_frames:
        value: 1000000
      replay_buffer_size:
        value: 800000
      curriculum:
        parameters:
          steps_stage_1:
            values: [200000, 350000, 500000]
          base_reward_keys:
            value: "gds"
          all_reward_keys:
            value: "gdcsax"
          num_updates_after_update:
            value: 50000
          reset_buffer:
            value: False

