program: /Users/tamino/dev/robot_learning/DRL-Traj-Planner/src/continous_training_sweep.py
method: grid
metric:
  name: eval/episode_success
  goal: maximize
parameters:
  alpha:
    values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  reward_mode:
    values: ["sum", "curriculum", "curriculum_step"]  # "multiply"
  seed:
    values: [1235, 2621, 12]  # 1235, 2621, 12, 52
  map_key:
    values: ['dynamic_convex_obstacle', 'static_nonconvex_obstacle', 'corridor']